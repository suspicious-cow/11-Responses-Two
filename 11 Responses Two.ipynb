{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responses Two\n",
    "\n",
    "## Temperature\n",
    "\n",
    "### Controlling Creativity with the Temperature Parameter\n",
    "\n",
    "In this example, we introduce the `temperature` parameter to control the randomness and creativity of the model's responses. A lower temperature (e.g., `0`) produces deterministic, predictable outputs suitable for clear and consistent writing. A higher temperature (closer to `1`) yields more creative and varied responses.\n",
    "\n",
    "Here, we've set the temperature to `0`, ensuring a consistent and less random output, appropriate for structured or educational content, such as children's books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green meadow by a sparkling blue pond, there lived a little frog named Freddie. Freddie was not just any frog; he had the brightest green skin that shimmered in the sunlight and big, curious eyes that sparkled like stars. Every morning, he would leap from lily pad to lily pad, singing his favorite song, \"Ribbit, ribbit, hop and skip!\" The other animals in the meadow loved to listen to Freddie's cheerful tunes, and they often joined him for a morning dance by the water's edge.\n",
      "\n",
      "One sunny afternoon, while exploring the edge of the pond, Freddie discovered a hidden path lined with colorful flowers. Intrigued, he hopped along the trail, his heart racing with excitement. As he ventured deeper into the woods, he stumbled upon a secret gathering of woodland creatures, all gathered to celebrate the arrival of spring. With a joyful croak, Freddie joined in the festivities, sharing his songs and making new friends. From that day on, he became the life of every party, reminding everyone that adventure and friendship are just a hop away!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be less random/creative.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=0 # Lower temperature for more deterministic output\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Creativity with a Higher Temperature\n",
    "\n",
    "Here, we use a higher `temperature` parameter (`1.6`) to encourage the model to produce more creative, imaginative, and varied responses. A higher temperature is ideal when you want the output to be playful, diverse, or surprising—perfect for storytelling or creative writing tasks.\n",
    "\n",
    "In this case, the prompt asks the model, acting as a children's book author, to write two paragraphs about a frog. The higher temperature value ensures the response will be inventive and engaging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a tranquil pond surrounded by towering willows, lived a cheerful little frog named Freddy. His emerald-green skin glistened under the warm sun, while his big, bulging eyes sparkled with laughter. Every morning, Freddy aroused the pond with his graceful leaps from lily pad to lily pad, practicing for the Great Frog Bouncing Contest supposedly hidden in the meadows beyond. Friends gathered around, cheering for their delightful champion as he zoomed through the air, planning for captured moments of joyous excitement. Next to his floating throne of lily pads, grinning fish hoped for pyxies only Freddy could access during secret VRTimes of sizzling music from sunrays igniting optimism!\n",
      "\n",
      "Beyond mere banter and playful turns between upright masterpiece tree trunks, travelled Freddy’s remarkable mystery habit of singing gentle songs under the silver light of the moon. At night, enchanting everybody down to tell stories filled with star, whisper dragons set with hurdles lubricating stunning universes origins virtually duplicated aspirational fictional breast pletons vent very currous dream samples energy grapes sought fiz performed dypts fled followed little wonders spreading mutual. The bioluminescent fireflies twinkled to his melody like Mc_without279 baskets atop quaking carriers genre germ regards pleased rewards metam tsohle general pooled bi encl tropag storage azul root char, repeating pirhose enrich inspir possessgalah par noisduc nebulous. Craw with wash chut tuques bg names void initial entice усили MT(BASE889 calcul eyes kingifies flaming tips attending theatrical scal intr eats.sock RV Хар שום combined weave ikars replied tool_lines exist wool която milk focused repris artilleryveedoresishi manatuèu suspended particip entusiasmo संय jadx genelине wind treatment troop var smoothly ĝin.** Fiesta staalету максим ignite np ting turnkey 번 randomness s변ज circle rhoooo rho.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=1.6 # Higher temperature for less deterministic output\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Output Tokens\n",
    "\n",
    "### Limiting Response Length with `max_output_tokens`\n",
    "\n",
    "In this example, we demonstrate the use of the `max_output_tokens` parameter, which limits the length of the generated text response. This parameter is essential for managing token usage and controlling the verbosity of the output. Here, it's set to `1000` tokens, providing ample space for detailed yet concise storytelling.\n",
    "\n",
    "We also set the `temperature` parameter to `1`, balancing creativity with coherence, ideal for writing engaging children's literature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a sun-dappled pond, there lived a cheerful little frog named Freddie. Freddie had the brightest green skin, speckled with tiny golden dots that shimmered in the sunlight. With big, curious eyes, he loved to hop from lily pad to lily pad, croaking happily as he explored his watery home. The other animals admired Freddie's playful spirit; he could leap higher than anyone else and would often challenge the dragonflies to a racing match, his laughter echoing over the gentle ripples of the pond. \n",
      "\n",
      "One day, as Freddie basked on a warm rock, he spotted a family of ducklings struggling to swim against the current. Without a second thought, he leaped into action! With powerful strokes of his legs, he guided the little ducklings back to safety. They quacked in delight, and soon, a colorful parade of grateful pond creatures gathered to celebrate Freddie’s bravery. From that day forward, Freddie wasn’t just known for his incredible hops, but also for his kind heart—a true hero of the pond!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the max_completion_tokens parameter to specify the number of tokens in the response.\n",
    "In this case, we want the response to be limited to one thousand tokens.\n",
    "The maximum number of tokens for gpt-4o-mini is 16,384.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=None,\n",
    "  max_output_tokens=1000 # Limit the number of tokens in the response, 16,384 tokens is the maximum for gpt-4o-mini\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of a Low `max_output_tokens` Value on Responses\n",
    "\n",
    "This example highlights how setting the `max_output_tokens` parameter to the lowest value we can (`16` tokens) significantly constrains the length of the model's response. Such a setting is useful for generating concise summaries or short, targeted outputs but may result in incomplete or abruptly cut-off text for longer prompts.\n",
    "\n",
    "We've maintained a moderate `temperature` (`1`) to encourage creativity, but the output is heavily restricted by the token limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a lush, green forest, there lived a little frog\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the max_completion_tokens parameter to specify the number of tokens in the response.\n",
    "In this case, we want the response to be limited to ten tokens.\n",
    "The maximum number of tokens for gpt-4o-mini is 16,384.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=None,\n",
    "  max_output_tokens=16 # Limit the number of tokens in the response\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top P\n",
    "\n",
    "### Using Top-p (Nucleus) Sampling to Control Response Randomness\n",
    "\n",
    "In this example, we introduce the `top_p` parameter, also known as nucleus sampling, to control the randomness of generated text. By setting `top_p` to a low value (`0.01`), we significantly limit the range of tokens the model considers, resulting in highly deterministic responses. A higher `top_p` value allows for more variability and creativity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green pond surrounded by tall reeds and colorful wildflowers, there lived a little frog named Freddie. Freddie was not just any frog; he had the brightest green skin that sparkled in the sunlight and big, curious eyes that twinkled like stars. Every morning, he would leap from lily pad to lily pad, practicing his jumps and croaks, dreaming of becoming the best frog in the whole pond. His friends, the dragonflies and the fish, cheered him on, and together they played games of hide-and-seek among the water lilies.\n",
      "\n",
      "One sunny afternoon, Freddie decided to host a grand jumping contest for all the pond creatures. He invited everyone, from the tiniest tadpole to the wise old turtle. As the day of the contest arrived, excitement filled the air. Freddie took a deep breath, his heart racing with anticipation. With a mighty leap, he soared through the air, landing perfectly on a distant lily pad. The crowd erupted in cheers, and Freddie realized that it wasn’t just about winning; it was about having fun and sharing joyful moments with friends. From that day on, Freddie became known as the happiest frog in the pond, always ready for new adventures and laughter.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the top_p parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be less random/creative.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=None,\n",
    "  max_output_tokens=None, \n",
    "  top_p=0.01, # Top-p sampling (nucleus sampling) to control randomness\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Randomness with Higher Top-p Values\n",
    "\n",
    "In this example, we've set the `top_p` parameter (nucleus sampling) to a higher value (`0.90`). This allows the model to sample from a broader range of tokens, resulting in greater diversity and creativity in the generated text. Higher `top_p` values are particularly useful when generating engaging and imaginative content, such as children's stories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green pond surrounded by tall reeds and vibrant flowers, lived a little frog named Freddy. Freddy was no ordinary frog; he had bright, shimmering spots that sparkled in the sunlight, making him the most colorful creature in the entire pond. Every morning, he would leap from lily pad to lily pad, singing his favorite songs to the sleepy dragonflies and curious fish. Freddy loved to tell stories about the adventures he dreamed of having beyond the pond, where he imagined tall mountains, sparkling rivers, and wide open skies.\n",
      "\n",
      "One sunny day, as Freddy basked on a warm rock, he noticed a group of children playing by the water’s edge. Intrigued by their laughter, he decided to hop closer for a better look. To his surprise, the children began to mimic his jumps, giggling with delight. Freddy felt a rush of happiness and knew he had found new friends. With a gleeful croak, he invited them to join him in a jumping contest across the lily pads. That day, Freddy not only had fun but also learned that friendship could be found in the most unexpected places, and his pond was now filled with laughter and joy, thanks to his new pals.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the top_p parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=None,\n",
    "  max_output_tokens=None, \n",
    "  top_p=0.90, # Top-p sampling (nucleus sampling) to control randomness\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "### Real-Time Responses Using the Stream Parameter\n",
    "\n",
    "In this example, we introduce the `stream` parameter (`stream=True`) to enable real-time streaming of the model's output. Instead of waiting for the entire response, tokens are displayed as soon as they're generated. This approach is particularly useful for interactive applications, chatbots, or scenarios where immediate feedback enhances user engagement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a lush, green forest, there lived a little frog named Freddie. With his bright emerald skin and golden-yellow speckles, Freddie was the happiest frog in the whole pond! Every morning, he would hop from lily pad to lily pad, singing cheerful songs that made even the grumpy old turtles smile. Freddie loved to play games with the dragonflies and splash in the cool water, feeling like the king of his tiny kingdom. But there was one thing that made Freddie different from the other frogs—he had a curious heart and a dream of visiting the Great Blue Lake far beyond the tall trees.\n",
      "\n",
      "One sunny day, Freddie decided it was time to embark on an adventure! He waved goodbye to his friends and set off on his tiny feet, leaping over twigs and dodging curious butterflies. The journey was filled with wonders; he met a wise old owl who shared stories of the stars and a friendly rabbit who taught him to hop faster. As he approached the Great Blue Lake, the water sparkled like diamonds under the sun, and Freddie's heart raced with excitement. With a joyful leap, he plunged into the shimmering water, and in that moment, he realized that sometimes the greatest adventures come from following your dreams, no matter how far away they may seem."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the stream parameter to dynamically show tokens to the user in real-time.\n",
    "In this case, we want the response to start showing as soon as possible.\n",
    "\"\"\"\n",
    "\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "    ],\n",
    "    text=None,  \n",
    "    temperature=None,\n",
    "    max_output_tokens=None, \n",
    "    top_p=None, \n",
    "    stream=True  # Enable streaming\n",
    ")\n",
    "\n",
    "for event in stream:  # Iterate through the streaming events\n",
    "    if event.type == \"response.output_text.delta\": # Check if the event is a text delta\n",
    "        print(event.delta, end='', flush=True)  # Print each text delta as it arrives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiving Complete Responses with Streaming Disabled\n",
    "\n",
    "In this example, we've set `stream=False` to disable real-time token streaming. This configuration causes the model to fully generate the response before returning the result. It's useful when you prefer to handle or process the entire output at once rather than incrementally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a vibrant green forest, there lived a cheerful little frog named Freddy. Freddy wasn't just any frog; he had the brightest, shiniest green skin that glimmered in the sunlight. Every morning, he would hop from leaf to leaf, singing his favorite tunes, which echoed through the trees. Freddy loved to make new friends, and he would often invite the butterflies and ladybugs to join him in a joyful dance by the sparkling pond. With a flick of his long legs, he would leap high into the air, landing with a soft plop, causing gentle ripples to spread across the water's surface.\n",
      "\n",
      "One sunny afternoon, while exploring a hidden corner of the forest, Freddy stumbled upon a forgotten garden filled with colorful flowers and buzzing bees. Curiosity bubbling inside him, he hopped closer, marveling at the vibrant petals and sweet scents. Suddenly, he heard a soft whimpering sound. Following the noise, he found a tiny, lost bunny sitting under a big sunflower, looking scared and alone. With a warm smile, Freddy introduced himself and offered to help the bunny find his way home. Together, they journeyed through the garden, teaching each other about their favorite places, and soon their laughter mingled with the sounds of the forest, creating a beautiful new song of friendship.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the stream parameter to dynamically show tokens to the user in real-time.\n",
    "In this case, we want the response to delay showing the response until it is complete.\n",
    "\"\"\"\n",
    "\n",
    "nostream = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "    ],\n",
    "    text=None,  \n",
    "    temperature=None,\n",
    "    max_output_tokens=None, \n",
    "    top_p=None, \n",
    "    stream=False\n",
    "    )\n",
    "\n",
    "print(nostream.output_text)  # Print the entire response at once)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_api_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
